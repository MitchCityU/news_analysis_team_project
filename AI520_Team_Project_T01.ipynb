{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a7a7eb",
   "metadata": {},
   "source": [
    "# AI520: Natural Processing Language for Artificial Intelligence\n",
    "Term: Summer 2025 \\\n",
    "Author: David Hiltzman \\\n",
    "Assignment: Team Project \\\n",
    "Team 01 \\\n",
    "Authors: \\\n",
    "Mitch Fade, David Hiltzman, Tyler Kepler, Jeff Nelson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d665366",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "This project will create a false news story detector using a publicly available Kaggle labeled dataset with known real and false stories. Data will first be preprocessed, and feature extraction will be performed. Classical machine learning (ML) methods and deep learning methods will be used to create classifiers of the preprocessed dataset and evaluated for effectiveness. Additionally, the explainability of the results will be analyzed to show which words contributed the most to the predictions. A false news detector may help bring clarity in a world of ever-growing misinformation and may give interesting results on which words are most common in fake news stories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d375cb",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2be99",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ad59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, GroupKFold, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, average_precision_score,\n",
    "    matthews_corrcoef, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e70563",
   "metadata": {},
   "source": [
    "### Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./data\")\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "# Base \"tells\" to remove up-front (mostly publisher/style/boilerplate)\n",
    "BASE_TELLS = {\n",
    "    \"reuters\",\"washington\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"sunday\",\n",
    "    \"nov\",\"oct\",\"sep\",\"edt\",\"london\",\"york\",\"mr\",\"rep\",\"sen\",\n",
    "    \"video\",\"image\",\"read\",\"watch\",\"featured\",\"getty\",\"breaking\",\"http\",\"https\",\"com\",\"pic\"\n",
    "}\n",
    "\n",
    "# How many top tokens (per class) to auto-ban after baseline model fit\n",
    "TOP_K_TELLS_PER_CLASS = 50\n",
    "\n",
    "# TF-IDF settings (word analyzer)\n",
    "WORD_MAX_FEATURES = 5000\n",
    "WORD_MIN_DF = 5\n",
    "WORD_MAX_DF = 0.8\n",
    "WORD_TOKEN_PATTERN = r\"(?u)\\b[a-zA-Z][a-zA-Z\\-']+\\b\"\n",
    "\n",
    "print(\"Configuration parameters set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24510d3e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879322c",
   "metadata": {},
   "source": [
    "### Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess a given text string by normalizing, tokenizing, \n",
    "    removing stop words, and lemmatizing.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed text string\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # Remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]   # Lemmatize\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalize column names by stripping whitespace and converting to lowercase.\"\"\"\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "def ensure_date_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Find a likely date column, parse to datetime, and write back to a unified 'date' column.\n",
    "    If no date-like column exists, create an empty 'date' column.\n",
    "    \"\"\"\n",
    "    candidates = [\n",
    "        \"date\", \"published\", \"publish_date\", \"publication_date\",\n",
    "        \"pub_date\", \"created_at\", \"time\", \"timestamp\"\n",
    "    ]\n",
    "    date_col = next((c for c in candidates if c in df.columns), None)\n",
    "    \n",
    "    if date_col is None:\n",
    "        df[\"date\"] = pd.NaT\n",
    "    else:\n",
    "        df[\"date\"] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    \n",
    "    # Write dates as ISO strings (YYYY-MM-DD); keep NaN if unknown\n",
    "    df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    return df\n",
    "\n",
    "def build_combined(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a 'combined' text field from 'processed_title' and 'processed_text'.\n",
    "    Safely handles missing values, converts to strings, strips whitespace, and\n",
    "    joins with a single space.\n",
    "    \"\"\"\n",
    "    df[\"processed_title\"] = df[\"processed_title\"].fillna(\"\").astype(str).str.strip()\n",
    "    df[\"processed_text\"]  = df[\"processed_text\"].fillna(\"\").astype(str).str.strip()\n",
    "    df[\"combined\"] = (df[\"processed_title\"] + \" \" + df[\"processed_text\"]).str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessing tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "print(\"Text preprocessing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba75ccf",
   "metadata": {},
   "source": [
    "### Advanced Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_report(name: str, model, X_test, y_test) -> None:\n",
    "    \"\"\"\n",
    "    Print a suite of metrics on a held-out test set.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n=== {name} — Held-out Test ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        print(\"ROC AUC:\", round(roc_auc_score(y_test, probs), 4))\n",
    "        print(\"AUCPR :\", round(average_precision_score(y_test, probs), 4))\n",
    "        print(\"MCC   :\", round(matthews_corrcoef(y_test, y_pred), 4))\n",
    "    else:\n",
    "        print(\"MCC   :\", round(matthews_corrcoef(y_test, y_pred), 4))\n",
    "\n",
    "def leak_safe_cv_f1(\n",
    "    X_text_train: List[str],\n",
    "    y_train: np.ndarray,\n",
    "    stop_words_list: List[str],\n",
    "    n_splits: int = 5\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute leak-safe StratifiedKFold F1 scores on raw training text.\n",
    "    Uses a scikit-learn Pipeline so TF-IDF is fit **inside each fold**, preventing\n",
    "    vocabulary/IDF leakage from train to validation.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            max_features=WORD_MAX_FEATURES,\n",
    "            token_pattern=WORD_TOKEN_PATTERN,\n",
    "            min_df=WORD_MIN_DF,\n",
    "            max_df=WORD_MAX_DF,\n",
    "            stop_words=stop_words_list\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)),\n",
    "    ])\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(pipe, X_text_train, y_train, cv=skf, scoring=\"f1\")\n",
    "    return scores\n",
    "\n",
    "def print_top_tokens(model: LogisticRegression, vectorizer: TfidfVectorizer, k: int = 25) -> None:\n",
    "    \"\"\"\n",
    "    Print top positive/negative tokens by coefficient magnitude from a trained LogisticRegression.\n",
    "    \"\"\"\n",
    "    coef = model.coef_[0]\n",
    "    feats = vectorizer.get_feature_names_out()\n",
    "    top_pos_idx = np.argsort(coef)[-k:][::-1]\n",
    "    top_neg_idx = np.argsort(coef)[:k]\n",
    "    print(\"Top TRUE tokens:\", [feats[i] for i in top_pos_idx])\n",
    "    print(\"Top FAKE tokens:\", [feats[i] for i in top_neg_idx])\n",
    "\n",
    "def analyze_errors(model, X_test_txt, X_test, y_test) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze model errors and return DataFrame with error analysis.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Build a test frame to inspect mistakes\n",
    "    test_df = pd.DataFrame({\n",
    "        \"text\": X_test_txt,\n",
    "        \"y_true\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"p_true\": model.predict_proba(X_test)[:, 1]\n",
    "    })\n",
    "    \n",
    "    # Most confident wrong predictions\n",
    "    wrong = test_df[test_df.y_true != test_df.y_pred].copy()\n",
    "    wrong[\"margin\"] = np.abs(wrong[\"p_true\"] - 0.5)\n",
    "    \n",
    "    print(\"Wrong predictions:\", len(wrong))\n",
    "    print(\"\\nTop 10 most confident errors:\")\n",
    "    top_errors = wrong.sort_values(\"margin\", ascending=False).head(10)[[\"y_true\",\"y_pred\",\"p_true\",\"text\"]]\n",
    "    for idx, row in top_errors.iterrows():\n",
    "        print(f\"True: {row['y_true']}, Pred: {row['y_pred']}, Prob: {row['p_true']:.3f}\")\n",
    "        print(f\"Text: {row['text'][:200]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Quick counts by error type\n",
    "    print(f\"\\nFalse positives (pred 1, true 0): {(wrong.y_pred.eq(1) & wrong.y_true.eq(0)).sum()}\")\n",
    "    print(f\"False negatives (pred 0, true 1): {(wrong.y_pred.eq(0) & wrong.y_true.eq(1)).sum()}\")\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "print(\"Advanced analysis functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b5a39",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3e68e",
   "metadata": {},
   "source": [
    "### Download, verify, and save Kaggle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8e1c9",
   "metadata": {},
   "source": [
    "#### Download Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"Created/verified data directory: {DATA_DIR}\")\n",
    "\n",
    "# Download dataset using kagglehub\n",
    "try:    \n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "    \n",
    "    # List files in the downloaded directory\n",
    "    downloaded_files = os.listdir(path)\n",
    "    print(\"Downloaded files:\", downloaded_files)\n",
    "    \n",
    "    # Look for True.csv and Fake.csv (or similar names)\n",
    "    true_file_candidates = [f for f in downloaded_files if 'true' in f.lower() and f.endswith('.csv')]\n",
    "    fake_file_candidates = [f for f in downloaded_files if 'fake' in f.lower() and f.endswith('.csv')]\n",
    "    \n",
    "    print(f\"True file candidates: {true_file_candidates}\")\n",
    "    print(f\"Fake file candidates: {fake_file_candidates}\")\n",
    "    \n",
    "    # Copy files to our data directory\n",
    "    if true_file_candidates and fake_file_candidates:\n",
    "        true_source = os.path.join(path, true_file_candidates[0])\n",
    "        fake_source = os.path.join(path, fake_file_candidates[0])\n",
    "        \n",
    "        true_dest = os.path.join(DATA_DIR, \"True.csv\")\n",
    "        fake_dest = os.path.join(DATA_DIR, \"Fake.csv\")\n",
    "        \n",
    "        shutil.copy2(true_source, true_dest)\n",
    "        shutil.copy2(fake_source, fake_dest)\n",
    "        \n",
    "        print(f\"Copied {true_file_candidates[0]} to {true_dest}\")\n",
    "        print(f\"Copied {fake_file_candidates[0]} to {fake_dest}\")\n",
    "        \n",
    "        # Set file paths for later use\n",
    "        true_file_path = true_dest\n",
    "        fake_file_path = fake_dest\n",
    "        dataset_ready = True\n",
    "        \n",
    "    else:\n",
    "        print(\"Could not find True.csv and Fake.csv files\")\n",
    "        print(\"Available files:\", downloaded_files)\n",
    "        dataset_ready = False\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"kagglehub not installed. Please install it with:\")\n",
    "    print(\"pip install kagglehub\")\n",
    "    dataset_ready = False\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error downloading dataset: {e}\")\n",
    "    print(\"\\nAlternative: Download manually from:\")\n",
    "    print(\"https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\")\n",
    "    print(\"Then place True.csv and Fake.csv in the ./data directory\")\n",
    "    dataset_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d4abb",
   "metadata": {},
   "source": [
    "#### Verify Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if files exist in data directory\n",
    "true_file_path = os.path.join(DATA_DIR, \"True.csv\")\n",
    "fake_file_path = os.path.join(DATA_DIR, \"Fake.csv\")\n",
    "\n",
    "if os.path.exists(true_file_path) and os.path.exists(fake_file_path):\n",
    "    dataset_ready = True\n",
    "    print(f\"Dataset files ready:\")\n",
    "    print(f\"  - {true_file_path}\")\n",
    "    print(f\"  - {fake_file_path}\")\n",
    "else:\n",
    "    print(f\"Dataset files not found in {DATA_DIR}\")\n",
    "    dataset_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb620e",
   "metadata": {},
   "source": [
    "#### Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ae970",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    # Load the datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    df_true = pd.read_csv(true_file_path)\n",
    "    df_fake = pd.read_csv(fake_file_path)\n",
    "    \n",
    "    # Normalize headers to avoid case/space issues\n",
    "    df_true = normalize_columns(df_true)\n",
    "    df_fake = normalize_columns(df_fake)\n",
    "    \n",
    "    # Make sure we have a usable 'date' column in both\n",
    "    df_true = ensure_date_column(df_true)\n",
    "    df_fake = ensure_date_column(df_fake)\n",
    "    \n",
    "    print(\"Datasets loaded successfully!\")\n",
    "    print(f\"True dataset shape: {df_true.shape}\")\n",
    "    print(f\"Fake dataset shape: {df_fake.shape}\")\n",
    "    print(f\"\\nTrue dataset columns: {df_true.columns.tolist()}\")\n",
    "    print(f\"Fake dataset columns: {df_fake.columns.tolist()}\")\n",
    "    \n",
    "    # Display first few rows to understand the data structure\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SAMPLE DATA - True News:\")\n",
    "    print(\"=\"*50)\n",
    "    print(df_true.head(2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SAMPLE DATA - Fake News:\")\n",
    "    print(\"=\"*50)\n",
    "    print(df_fake.head(2))\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready. Please run the previous cell successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147d09d",
   "metadata": {},
   "source": [
    "###  Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788dee4",
   "metadata": {},
   "source": [
    "#### Data Validation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    # Guard for missing title/text columns\n",
    "    required = {\"title\", \"text\"}\n",
    "    missing_true = required - set(df_true.columns)\n",
    "    missing_fake = required - set(df_fake.columns)\n",
    "    if missing_true:\n",
    "        raise KeyError(f\"True.csv missing required columns: {missing_true}\")\n",
    "    if missing_fake:\n",
    "        raise KeyError(f\"Fake.csv missing required columns: {missing_fake}\")\n",
    "    \n",
    "    # Apply preprocessing to title and text columns\n",
    "    print(\"Preprocessing text data...\")\n",
    "    df_true[\"processed_title\"] = df_true[\"title\"].astype(str).apply(preprocess_text)\n",
    "    df_fake[\"processed_title\"] = df_fake[\"title\"].astype(str).apply(preprocess_text)\n",
    "    df_true[\"processed_text\"] = df_true[\"text\"].astype(str).apply(preprocess_text)\n",
    "    df_fake[\"processed_text\"] = df_fake[\"text\"].astype(str).apply(preprocess_text)\n",
    "    print(\"Preprocessing complete!\")\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a552d27",
   "metadata": {},
   "source": [
    "#### Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    # Save preprocessed data\n",
    "    df_true[[\"processed_title\", \"processed_text\", \"date\"]].to_csv(\"preprocessed_True.csv\", index=False)\n",
    "    df_fake[[\"processed_title\", \"processed_text\", \"date\"]].to_csv(\"preprocessed_Fake.csv\", index=False)\n",
    "    \n",
    "    print(\"Preprocessed data saved to CSV files\")\n",
    "    print(\"Processed True dataset sample:\")\n",
    "    print(df_true[[\"processed_title\", \"processed_text\", \"date\"]].head())\n",
    "    print(\"\\nProcessed Fake dataset sample:\")\n",
    "    print(df_fake[[\"processed_title\", \"processed_text\", \"date\"]].head())\n",
    "else:\n",
    "    print(\"Cannot save - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d23966",
   "metadata": {},
   "source": [
    "### Enhanced Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef8f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    # Load preprocessed data\n",
    "    df_fake_processed = pd.read_csv(\"preprocessed_Fake.csv\")\n",
    "    df_true_processed = pd.read_csv(\"preprocessed_True.csv\")\n",
    "    \n",
    "    # Ensure labels (0=fake, 1=true)\n",
    "    if \"label\" not in df_fake_processed.columns: \n",
    "        df_fake_processed[\"label\"] = 0\n",
    "    if \"label\" not in df_true_processed.columns: \n",
    "        df_true_processed[\"label\"] = 1\n",
    "    \n",
    "    # Build combined text\n",
    "    df_fake_processed = build_combined(df_fake_processed)\n",
    "    df_true_processed = build_combined(df_true_processed)\n",
    "    \n",
    "    # Merge, drop empties and exact duplicates\n",
    "    df_combined = pd.concat([df_fake_processed, df_true_processed], ignore_index=True)\n",
    "    df_combined = df_combined[df_combined[\"combined\"] != \"\"].reset_index(drop=True)\n",
    "    orig_n = len(df_combined)\n",
    "    df_combined = df_combined.drop_duplicates(subset=[\"combined\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Loaded shapes — fake: {df_fake_processed.shape}  true: {df_true_processed.shape}  merged: {df_combined.shape}\")\n",
    "    print(f\"Dropped exact duplicate rows: {orig_n - len(df_combined)} (remaining: {len(df_combined)})\")\n",
    "    \n",
    "    # Features/labels\n",
    "    X_text = df_combined[\"combined\"].astype(str).tolist()\n",
    "    y = pd.to_numeric(df_combined[\"label\"], errors=\"raise\").to_numpy(dtype=np.int8)\n",
    "    \n",
    "    print(f\"Combined dataset shape: {df_combined.shape}\")\n",
    "    print(f\"Label distribution:\\n{pd.Series(y).value_counts()}\")\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3696bef",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    # Stratified random split (no time-based aspect)\n",
    "    X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    print(\"Train size:\", len(y_train), \" Test size:\", len(y_test))\n",
    "    print(\"Data split completed\")\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb3bc1",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eac553",
   "metadata": {},
   "source": [
    "### Enhanced Baseline Model with Leak-Safe CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ENHANCED BASELINE MODEL WITH LEAK-SAFE CV\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # CV on TRAIN with base tells removed\n",
    "    custom_stop = set(ENGLISH_STOP_WORDS) | BASE_TELLS\n",
    "    stop_words_list = sorted(custom_stop)\n",
    "    cv_scores = leak_safe_cv_f1(X_train_txt, y_train, stop_words_list, n_splits=5)\n",
    "    print(\"Leak-safe StratifiedKFold F1 (train):\", cv_scores.mean())\n",
    "    print(\"Per-fold F1:\", cv_scores)\n",
    "    \n",
    "    # Fit baseline model and evaluate on TEST\n",
    "    vec_word = TfidfVectorizer(\n",
    "        max_features=WORD_MAX_FEATURES,\n",
    "        token_pattern=WORD_TOKEN_PATTERN,\n",
    "        min_df=WORD_MIN_DF,\n",
    "        max_df=WORD_MAX_DF,\n",
    "        stop_words=stop_words_list\n",
    "    )\n",
    "    X_train = vec_word.fit_transform(X_train_txt)\n",
    "    X_test = vec_word.transform(X_test_txt)\n",
    "    \n",
    "    model_base = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "    model_base.fit(X_train, y_train)\n",
    "    \n",
    "    evaluate_and_report(\"Enhanced Baseline (word TF-IDF + base tells removed)\", model_base, X_test, y_test)\n",
    "    print_top_tokens(model_base, vec_word, k=25)\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248f36d",
   "metadata": {},
   "source": [
    "### Auto-Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"AUTO-PRUNED MODEL (REMOVING TOP CORRELATED TOKENS)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Auto-prune top label-correlated tokens, retrain, re-evaluate\n",
    "    coef = model_base.coef_[0]\n",
    "    feats = vec_word.get_feature_names_out()\n",
    "    top_pos = [w for _, w in sorted(zip(coef, feats), reverse=True)[:TOP_K_TELLS_PER_CLASS]]\n",
    "    top_neg = [w for _, w in sorted(zip(coef, feats))[:TOP_K_TELLS_PER_CLASS]]\n",
    "    auto_ban = set(top_pos + top_neg)\n",
    "    \n",
    "    print(f\"Auto-banned {len(auto_ban)} highly correlated tokens\")\n",
    "    \n",
    "    stop_words_list_pruned = sorted(set(stop_words_list) | auto_ban)\n",
    "    cv_scores_pruned = leak_safe_cv_f1(X_train_txt, y_train, stop_words_list_pruned, n_splits=5)\n",
    "    print(\"Leak-safe StratifiedKFold F1 (train) — PRUNED:\", cv_scores_pruned.mean())\n",
    "    print(\"Per-fold F1 (pruned):\", cv_scores_pruned)\n",
    "    \n",
    "    vec_word_pruned = TfidfVectorizer(\n",
    "        max_features=WORD_MAX_FEATURES,\n",
    "        token_pattern=WORD_TOKEN_PATTERN,\n",
    "        min_df=WORD_MIN_DF,\n",
    "        max_df=WORD_MAX_DF,\n",
    "        stop_words=stop_words_list_pruned\n",
    "    )\n",
    "    X_train_p = vec_word_pruned.fit_transform(X_train_txt)\n",
    "    X_test_p = vec_word_pruned.transform(X_test_txt)\n",
    "    \n",
    "    model_pruned = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "    model_pruned.fit(X_train_p, y_train)\n",
    "    \n",
    "    evaluate_and_report(\"PRUNED (auto-ban top tokens per class)\", model_pruned, X_test_p, y_test)\n",
    "    print_top_tokens(model_pruned, vec_word_pruned, k=25)\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e8d49",
   "metadata": {},
   "source": [
    "### Character N-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95696761",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CHARACTER N-GRAM MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Vectorize with character n-grams\n",
    "    vectorizer_char = TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(3, 4),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        max_features=30000,\n",
    "        lowercase=True\n",
    "    )\n",
    "    X_train_char = vectorizer_char.fit_transform(X_train_txt)\n",
    "    X_test_char = vectorizer_char.transform(X_test_txt)\n",
    "    print(\"Char TF-IDF shapes:\", X_train_char.shape, X_test_char.shape)\n",
    "    \n",
    "    # Train & evaluate character n-gram model\n",
    "    model_char = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "    model_char.fit(X_train_char, y_train)\n",
    "    \n",
    "    evaluate_and_report(\"Character N-grams (3-4)\", model_char, X_test_char, y_test)\n",
    "    \n",
    "    # Top positive/negative character n-grams\n",
    "    coef_char = model_char.coef_[0]\n",
    "    feats_char = vectorizer_char.get_feature_names_out()\n",
    "    top_pos_char = np.argsort(coef_char)[-25:][::-1]\n",
    "    top_neg_char = np.argsort(coef_char)[:25]\n",
    "    print(\"Top TRUE (class 1) char n-grams:\", [feats_char[i] for i in top_pos_char])\n",
    "    print(\"Top FAKE (class 0) char n-grams:\", [feats_char[i] for i in top_neg_char])\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb2e9d",
   "metadata": {},
   "source": [
    "### Traditional Classifiers with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7063b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TRADITIONAL CLASSIFIERS WITH ENHANCED FEATURES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Random Forest\n",
    "    print(\"\\nRANDOM FOREST CLASSIFIER\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    evaluate_and_report(\"Random Forest (Enhanced Features)\", rf_model, X_test, y_test)\n",
    "    \n",
    "    # Linear SVM\n",
    "    print(\"\\nLINEAR SVM CLASSIFIER\")\n",
    "    svm_model = make_pipeline(\n",
    "        StandardScaler(with_mean=False),\n",
    "        LinearSVC(dual=\"auto\", C=1.0, tol=1e-3, max_iter=5000, random_state=RANDOM_STATE)\n",
    "    )\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    evaluate_and_report(\"Linear SVM (Enhanced Features)\", svm_model, X_test, y_test)\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33bc98",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd54a1",
   "metadata": {},
   "source": [
    "### Confusion Matrices Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CONFUSION MATRICES VISUALIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create confusion matrices\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(model_base, X_test, y_test, ax=axes[0,0])\n",
    "    axes[0,0].set_title(\"Enhanced Baseline\")\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(model_pruned, X_test_p, y_test, ax=axes[0,1])\n",
    "    axes[0,1].set_title(\"Auto-Pruned\")\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(model_char, X_test_char, y_test, ax=axes[1,0])\n",
    "    axes[1,0].set_title(\"Character N-grams\")\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test, ax=axes[1,1])\n",
    "    axes[1,1].set_title(\"Random Forest\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ddf94",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ERROR ANALYSIS - ENHANCED BASELINE MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    error_df = analyze_errors(model_base, X_test_txt, X_test, y_test)\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")\n",
    "\n",
    "# Cell 19: Final Model Comparison Summary\n",
    "if dataset_ready:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"All models trained on the same train/test split (random_state=42)\")\n",
    "    print(\"Dataset size:\", df_combined.shape[0], \"samples\")\n",
    "    print(\"Enhanced features with leak-safe cross-validation\")\n",
    "    print(\"Train/Test split: 80/20\")\n",
    "    print(\"Advanced preprocessing with auto-pruning of correlated tokens\")\n",
    "    print(\"Character n-gram features for style-based detection\")\n",
    "    print(\"Comprehensive evaluation metrics (ROC AUC, AUCPR, MCC)\")\n",
    "    print(\"\\nKey Features Implemented:\")\n",
    "    print(\"- Leak-safe cross-validation using Pipeline\")\n",
    "    print(\"- Publisher/style 'tells' removal\")\n",
    "    print(\"- Auto-pruning of highly correlated tokens\")\n",
    "    print(\"- Character n-gram analysis for stylistic patterns\")\n",
    "    print(\"- Comprehensive error analysis\")\n",
    "    print(\"- Multiple evaluation metrics beyond accuracy\")\n",
    "else:\n",
    "    print(\"Cannot proceed - dataset not ready.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai520_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
